parser <- function( file, encoding = "unknown", text ){
	if( !missing( text ) ){
		tf <- tempfile( ); on.exit( unlink( tf ) )
		cat( text , file = tf, sep = "\n" )
		file <- tf
	}
	p <- .External( "do_parser", file = file, encoding = encoding )
	
	# <TODO> do this in C
	data <- as.data.frame( attr(p,"data") )
	colnames( data ) <- c( "line1", "col1", "byte1", 
		 	"line2", "col2", "byte2", "token", "id", "parent" )
	m <- match( data$token, symbols$token )
	data$token.desc <- symbols$desc [ m ]
	data$type <- symbols$type[m]
	attr( p, "data" ) <- data
	# </TODO>
	p
}

#' parses the grammar.output file that is generated by bison
grammar.symbols <- function(  ){
	# the output file from bison
	gram.output.file <- system.file( "gram.output", package = "highlight" )
	rl <- readLines( gram.output.file ) 
	
	.extract <- function( start.rx, end.rx, type = "terminal" ){
		start <- grep( start.rx, rl )[1] + 1L
		end <- grep( end.rx, rl)[1] - 1L
		
		rl <- rl[ start:end ]
		rx <- "(^.*) \\((\\d+)\\).*"
		rl <- grep( rx, rl, perl = T, value = T )
		desc   <- gsub( rx, "\\1", rl, perl = TRUE )
		token  <- as.integer( gsub( rx, "\\2", rl, perl = TRUE ) )
		data.frame( desc = desc, token = token, 
			type = rep.int( type , length(token) ), 
			stringsAsFactors = FALSE )
	}
	rbind( 
		.extract( 
			"^Terminals, with rules where they appear",
			"^Nonterminals, with rules where they appear", 
			TRUE ), 
		.extract( 
			"^Nonterminals, with rules where they appear",
			"^state 0", 
			FALSE )
		)
}

#' counts the number of bytes and columns in each line of the file
#'
#' @param file file to analyze
#' @param encoding encoding to assume for the file
count.chars <- function( file, encoding = "unknown" ){
	out <- .External( "do_countchars", file = file, encoding = encoding )
	dimnames(out) <- list( 1:nrow(out), c("char", "byte") )
	out
}

#' counts the number of lines of a file
#' 
#' @param file file from which to count lines
nlines <- function( file ){
	.External( "do_nlines", file = file )
}

